---
title: "Prepare data"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = here::here())
library(here)
library(emuR)
library(wrassp)
library(tidyverse)
library(rticulate)
library(tuneR)
```

# Prepare emuDB

```{r emudb}
alb_ipa <- "./data/alb-ipa_emuDB"
dataframes <- "./data/dataframes"

alb_ipa_db <- load_emuDB(alb_ipa, verbose = TRUE)
alb_ipa_sql <- alb_ipa_db$connection
alb_ipa_items <- tbl(alb_ipa_sql, "items")
alb_ipa_links <- tbl(alb_ipa_sql, "links") %>% select(-label)
alb_ipa_labels <- tbl(alb_ipa_sql, "labels")

attach(loadNamespace("emuR"), name = "emuR")
source("./code/config/emuR-patch.R")
```

# Read metadata

```{r metadata}
participants <- read_csv("./data/metadata/participants.csv") %>%
  select(-notes)

stimuli <- read_csv("./data/metadata/stimuli.csv") %>%
  mutate(
    order_id = str_pad(order_id, 2, pad = "0"),
    gloss = str_replace_all(gloss, c(" " = "_")),
    gloss = str_remove_all(gloss, "[,\\?]"),
    gloss = str_to_lower(gloss),
    order_fname = str_glue("{order_id}_{gloss}.wav") 
  )
```

# IPA list 

```{r ipa-list}
ipa_list <- list(
  vowels_repl = list("@" = "\u025C", "o" = "\u0254"),
  vowels = list(i = "i", y = "y", u = "u", e = "e", roe = "\u025C", o = "\u0254", a = "a"),
  cons_repl = list(
    "g" = "\u261",
    "D" = "\uF0", "T" = "\u3B8", "S" = "\u283", "Z" = "\u292",
    "tS" = "t\u283", "dZ" = "d\u29", "c" = "t\u33B\u283\u33B", "J\\\\" = "d\u33B\u292\u33B"
  ),
  plos = list("p", "t", "k", "b", "d", "\u261"),
  fric = list("f", "\u3B8", "s", "\u283", "h", "v", "\uF0", "z", "\u292"),
  affr = list("ts", "t\u283", "t\u33B\u283\u33B", "dz", "d\u292", "d\u33B\u292\u33B"),
  places = list("labial", "dental", "alveolar", "apico-postalveolar", "lamino-postalveolar", "glottal")
)
ipa_list$cons <- c(ipa_list$plos, ipa_list$fric, ipa_list$affr)
```

# Prepare EMU data

## Formants

First, we query the emuDB to get the vowels in the relevant example words.

```{r vow}
vow <- alb_ipa_db %>%
  # Get vowels from the vowel-words in the MAU level
  query(
  "[MAU == p -> #MAU == e| i | y | u | @ | o | a]",
  bundlePattern = "[0-9]*-(peri|por|puro|pyk3|pik3|p3r|para)"
) %>%
  # Requery each vowel segment to get the word from the ORT-MAU level
  bind_cols(
    requery_hier(alb_ipa_db, ., "ORT-MAU", timeRefSegmentLevel = "MAU") %>% select(labels) %>% rename(word = labels)
  ) %>%
  left_join(y = participants)
```

Now we can get formants from the midpoint of the vowels.

```{r formants}
formants <- get_trackdata(
  alb_ipa_db,
  seglist = vow,
  # Get values from mid-point
  cut = 0.5,
  npoints = 1,
  ssffTrackName = "FORMANTS",
  resultType = "tibble"
) %>%
  rename(
    F1 = T1,
    F2 = T2,
    F3 = T3,
    speaker = session
  ) %>%
  select(speaker, gender, labels, word, bundle, F1, F2, F3, start, end, sample_start, sample_end, times_orig) %>%
  mutate(
    vowel = str_replace_all(labels, unlist(ipa_list$vowels_repl)),
    vowel = factor(vowel, levels = ipa_list$vowels)
  ) %>%
  group_by(speaker) %>%
  mutate(
    F1.z = scale(F1),
    F2.z = scale(F2)
  ) %>%
  ungroup() %>%
  mutate(
    F1.z.hz = (F1.z * sd(F1)) + mean(F1),
    F2.z.hz = (F2.z * sd(F2)) + mean(F2),
    F1.z.bark = bark(F1.z.hz),
    F2.z.bark = bark(F2.z.hz),
    F2_F1.z.hz = F2.z.hz - F1.z.hz
  )
```

We now save the tibble.

```{r save-formants}
saveRDS(formants, here::here(dataframes, "formants.rds"))
```

## VOT

Query the database for the releases.

```{r vot}
vot <- alb_ipa_items %>%
  filter(level %in% c("RELS", "VOI")) %>%
  mutate(times = sample_point/sample_rate) %>%
  left_join(y = alb_ipa_links %>% rename(item_id = to_id)) %>%
  left_join(y = alb_ipa_labels %>% rename(from_id = item_id)) %>%
  select(session, bundle, level, times, label) %>%
  pivot_wider(names_from = "level", values_from = "times") %>%
  as_tibble() %>%
  mutate(
    vot = (VOI - RELS) * 1000,
    consonant = str_replace_all(label, unlist(ipa_list$cons_repl)),
    consonant = factor(consonant, levels = c(ipa_list$plos, ipa_list$affr))
  ) %>%
  rename(speaker = session)
```


```{r save-vot}
saveRDS(vot, here::here(dataframes, "vot.rds"))
```

## Intonation

First, we query the emuDB to get the relevant sentences.

```{r vow-f0}
vow_f0 <- alb_ipa_db %>%
  # Get vowels from the intonation-sentences in the MAU level
  query(
    "MAU !~ <p:>",
    bundlePattern = "[0-9]*-(broad*|polar*|narrow*)"
  ) %>%
  # Requery each vowel segment to get the word from the ORT-MAU level
  bind_cols(
    requery_hier(alb_ipa_db, ., "ORT-MAU", timeRefSegmentLevel = "MAU") %>% select(labels) %>% rename(word = labels)
  )
```

```{r f0}
f0 <- alb_ipa_db %>%
  get_trackdata(
    vow_f0,
    ssffTrackName = "F0"
  ) %>%
  unite("token", session, bundle, remove = FALSE) %>%
  group_by(token) %>%
  mutate(
    sentence_dur = max(end) - min(start),
    norm_timepoint = ((times_orig - (min(start)))/sentence_dur),
    sentence_type = factor(substring(bundle, 5)),
    sentence = recode(
      sentence_type,
      "broad-focus" = "(a) Lena lau murin.",
      "narrow-focus" = "(b) Lena lau murin, jo lulen.",
      "polar-q" = "(c) A e lau Lena murin?",
      "narrow-focus-q" = "(d) Çfarë lau Lena?"
    )
  ) %>%
  left_join(y = participants) %>%
  rename(
    "f0" = "T1",
    "segment" = "labels",
    "speaker" = "session"
  )

f0 <- f0 %>%
  left_join(
    y = f0 %>%
      select(speaker, sentence, token, sentence_type) %>%
      unique() %>%
      ungroup() %>%
      mutate(number = 1) %>%
      group_by(speaker, sentence_type) %>%
      mutate(repetition = as.factor(cumsum(number))) %>%
      ungroup() %>%
      select(speaker, sentence, token, repetition)
  ) %>%
  filter(
    f0 != 0,
    !(segment %in% c("tS", "f"))
  ) %>%
  select(speaker, gender, segment, word, sentence, sentence_type, repetition, f0, norm_timepoint, times_orig, sentence_dur, token)
```

And we now save the tibble.

```{r save-f0}
saveRDS(f0, here::here(dataframes, "f0.rds"))
```

```{r syl-f0}
syl <- query(alb_ipa_db, "SYL =~ .*", calcTimes = T) %>%
  filter(labels != "<p:>")

syl_f0 <- get_trackdata(alb_ipa_db, seglist = syl, ssffTrackName = "F0", cut = 0.5) %>%
  group_by(session, bundle) %>%
  mutate(
    sentence_dur = max(end) - min(start),
    norm_timepoint = ((times_orig - (min(start)))/sentence_dur),
    start_norm = (start - min(start)) / sentence_dur,
    end_norm = (end - min(start)) / sentence_dur
  ) %>%
  rename(f0 = "T1", speaker = "session") %>%
  mutate(
    sentence_type = str_sub(bundle, 5),
    sentence = recode(
      sentence_type,
      "broad-focus" = "(a) Lena lau murin.",
      "narrow-focus" = "(b) Lena lau murin, jo lulen.",
      "polar-q" = "(c) A e lau Lena murin?",
      "narrow-focus-q" = "(d) Çfarë lau Lena?"
      )
  )
syl_f0[syl_f0$labels == "çfar(ë)",]$f0 <- 250
```

```{r save-syl-f0}
saveRDS(syl_f0, here::here(dataframes, "syl_f0.rds"))
```


## Spectral DFT and moments

```{r affr-rels}
affr_rels = query(
  alb_ipa_db,
  "RELS =~ .*",
  bundlePattern = "[0-9]*-(cica|xixa|5aji|xhaja|qava|gjaku)", 
  calcTimes = T
) %>%
  select(start, session, bundle) %>%
  rename(rel_start = start)
```


```{r spect-segs}
spectr_segs <- query(
  alb_ipa_db,
  "[MAU == <p:> -> #MAU == f|v|T|D|s|z|S|Z|h|c|dz|dZ|J\\|ts|tS]",
  bundlePattern = "[0-9]*-"
) %>%
  filter(str_detect(bundle, "(narrow|story)", negate = T)) %>%
  left_join(y = affr_rels) %>%
  mutate(
    start = case_when(
      !is.na(rel_start) ~ rel_start,
      TRUE ~ start
    )
  )
```

```{r spect-dft}
# Get dft in wide format
spect_dft <- get_trackdata(
  alb_ipa_db,
  seglist = spectr_segs,
  ssffTrackName = "dft",
  resultType = "tibble",
  cut = 0.5
) %>%
  mutate(
    consonant = str_replace_all(labels, unlist(ipa_list$cons_repl)),
    consonant = factor(consonant, levels = c(ipa_list$fric, ipa_list$affr))
  )

spect_dft_l <- convert_wideToLong(spect_dft, calcFreqs = T)
```

```{r spect-moments}
# Get spectral moments
spect_moments <- spect_dft_l %>%
  filter(freq < 10000) %>%
  group_by(labels, sl_rowIdx) %>%
  do(data_frame(moments = moments(.$track_value,.$freq, minval = TRUE))) %>%
  mutate(moment_num = paste0("moment_", 1:(table(sl_rowIdx)))) %>%
  pivot_wider(names_from = "moment_num", values_from = "moments") %>%
  mutate(
    consonant = str_replace_all(labels, unlist(ipa_list$cons_repl)),
    consonant = factor(consonant, levels = c(ipa_list$fric, ipa_list$affr)),
    voicing = ifelse(
      consonant %in% c("f", "θ", "s", "ʃ", "ts", "tʃ", "t\u33B\u283\u33B", "h"),
      "voiceless",
      "voiced"
    ),
    voicing = factor(voicing, levels = c("voiceless", "voiced")),
    poa = case_when(
      consonant %in% c("f", "v") ~ "labial",
      consonant %in% c("s", "z", "ts", "dz") ~ "alveolar",
      consonant %in% c("θ", "ð") ~ "dental",
      consonant %in% c("tʃ", "dʒ", "ʃ", "ʒ") ~ "apico-postalveolar",
      consonant %in% c("t\u33B\u283\u33B", "d\u33B\u292\u33B") ~ "lamino-postalveolar",
      consonant %in% c("h") ~ "glottal"
    ),
    poa = factor(poa, levels = ipa_list$places),
    manner = ifelse(
      consonant %in% c("f", "v", "θ", "ð", "s", "z", "ʃ", "ʒ", "h"),
      "fricatives",
      "affricates"
    ),
    manner = factor(manner, levels = c("fricatives", "affricates")),
    voicing_manner = factor(
      paste(voicing, manner),
      levels = c("voiceless fricatives", "voiceless affricates", "voiced fricatives", "voiced affricates")
    )
  )

spect_moments %>%
  group_by(labels) %>%
  summarise(mean = mean(moment_1), sd = sd(moment_1))
```

```{r save-spect}
saveRDS(spect_dft_l, file = "./data/dataframes/spect_dft_l.rds")
saveRDS(spect_moments, file = "./data/dataframes/spect_moments.rds")
```

# Prepare UTI data

```{r uti}
cols <- c(
  "rec_date",
  "time",
  "prompt"
)

uti_laterals <- read_aaa("./data/ultrasound/laterals-splines.txt", column_names = cols)

uti_vowels <- read_aaa("./data/ultrasound/vowels-splines.txt", column_names = cols)

uti_palate <- read_aaa("./data/ultrasound/palate-spline.txt", column_names = cols)
```

```{r save-uti}
saveRDS(uti_laterals, file = "./data/dataframes/uti-laterals.rds")
saveRDS(uti_vowels, file = "./data/dataframes/uti-vowels.rds")
saveRDS(uti_palate, file = "./data/dataframes/uti-palate.rds")
```


# Illustrative recordings

```{r illustr}
illustr <- here("data", "recordings", "derived", "illustr")
dir.create(illustr, showWarnings = F)
words_out <- here(illustr, "words")
dir.create(words_out, showWarnings = F)
cons_out <- here(illustr, "consonants")
dir.create(cons_out, showWarnings = F)
vows_out <- here(illustr, "vowels")
dir.create(vows_out, showWarnings = F)
stress_out <- here(illustr, "stress")
dir.create(stress_out, showWarnings = F)
seglist_out <- here(illustr, "alb-ipa_txt_col_from_seglist")

s04_words <- query(
  alb_ipa_db,
  "ORT-MAU =~ .*",
  sessionPattern = "s04",
  timeRefSegmentLevel = "MAU"
) %>%
mutate(
  id = as.numeric(str_sub(bundle, 1, 3)),
  sample_start = sample_start - round(44.1 * 200),
  sample_end = sample_end + round(44.1 * 200),
  start = start - 200,
  end = end + 200
) %>%
filter(labels != "", id < 126)

export_seglistToTxtCollection(alb_ipa_db, s04_words, illustr)

seglist <- read_csv(here(seglist_out, "seglist.csv")) %>%
  mutate(number = 1) %>%
  group_by(labels) %>%
  mutate(
    repetition = as.factor(cumsum(number)),
    word = str_sub(bundle, 5),
    file_name = str_glue("{word}-{repetition}.wav")
  ) %>%
  ungroup() %>%
  rename(spelling = labels) %>%
  left_join(y = stimuli)

unique_words <- seglist %>%
  select(word, order_fname, example_type) %>%
  distinct() %>%
  filter(example_type %in% c("consonants", "vowels", "stress"))
file_names <- seglist$file_name
wavs <- list.files(seglist_out, "*.wav")

file.rename(here(seglist_out, wavs), here(seglist_out, file_names))

# sil <- silence(0.2, xunit = "time", bit = 16, pcm = T)

for (i in 1:nrow(unique_words)) {
  word <- unique_words$word[i]
  order_fname <- unique_words$order_fname[i]
  example_type <- unique_words$example_type[i]
  firstw <- readWave(str_glue("{seglist_out}/{word}-1.wav"))
  secondw <- readWave(str_glue("{seglist_out}/{word}-2.wav"))
  thirdf <- str_glue("{seglist_out}/{word}-3.wav")
  # jan3 only has 2 repetitions, so we need the following
  if (file.exists(thirdf)) {
    thirdw <- readWave(thirdf)
  } else {
    thirdw <- silence(0.001, xunit = "time", bit = 16, pcm = T)
  }
  
  combined <- tuneR::bind(firstw, secondw, thirdw)
  writeWave(combined, str_glue("{illustr}/{example_type}/{order_fname}"))
}

unlink(seglist_out, recursive = T)
unlink(words_out, recursive = T)

dir.create("./data/recordings/derived/illustr/intonation", showWarnings = F)

file.copy(
  from = "./data/alb-ipa_emuDB/s05_ses/130-broad-focus_bndl/130-broad-focus.wav",
  to = "./data/recordings/derived/illustr/intonation/40_declarative.wav"
)

file.copy(
  from = "./data/alb-ipa_emuDB/s01_ses/134-narrow-focus_bndl/134-narrow-focus.wav",
  to = "./data/recordings/derived/illustr/intonation/41_contrastive_focus.wav"
)

file.copy(
  from = "./data/alb-ipa_emuDB/s01_ses/132-polar-q_bndl/132-polar-q.wav",
  to = "./data/recordings/derived/illustr/intonation/42_polar_q.wav"
)

file.copy(
  from = "./data/alb-ipa_emuDB/s04_ses/132-narrow-focus-q_bndl/132-narrow-focus-q.wav",
  to = "./data/recordings/derived/illustr/intonation/43_content_q.wav"
)

file.copy(
  from = "./data/alb-ipa_emuDB/s04_ses/138-story_bndl/138-story.wav",
  to = "./data/recordings/derived/illustr/north_wind_and_sun.wav"
)
```

# Recordings for example figures

```{r examples}
examples_out <- here("data", "recordings", "derived", "examples")
dir.create(examples_out, showWarnings = F)

export_TextGridCollection(
  alb_ipa_db,
  examples_out,
  sessionPattern = "s04",
  bundlePattern = "018-pata|036-kati|038-qava|002-gjaku|027-rrapi|035-peri|008-perde",
  timeRefSegmentLevel = "MAU"
)
```

