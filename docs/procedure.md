# Data processing procedure

## Recording

Speakers were recorded in the Phonetics Laboratory at the IPS.

The raw (original) recordings are saved in `data/recordings/raw/` with the name template `Subject_<00>_<GENDER>.wav`, where `<00>` is the speaker's ID number and `<GENDER>` is either `Female` or `Male`.
The raw recordings are stereo audio files.
These have been converted to mono (same file name plus `_mono` suffix).
The TextGrids in `data/recordings/raw/` were manually created to specify intervals in the audio containing the word list, the sentences, the story (tier 1 `type`, possible labels `words`, `sentences`,  `story`), and intervals the audio within which is to be silenced (tier 2 `silenced`, label `silence`).

## Force-alignment

Force-aligned phonetic segmentation was achieved with the BAS web service [Pipeline without ASR](https://clarin.phonetik.uni-muenchen.de/BASWebServices/interface/Pipeline).

The service requires two inputs:

- The audio files to force-align,
- and the respective transcripts in original spelling (Albanian in this case).

The Praat script `code/get_prealign_chunks.praat` was run to chunk each speaker's audio file into three separate audio files, containing the word list, the sentences, and the story (the files are named `words.wav`, `sentences.wav`, `story.wav` respectively).
The transcript files (`words.txt`, `sentence.txt`, `story.txt`) were manually created to reflect the actual order of the stimuli in the recordings for each speaker.

The service was run with the following settings:

- Pipeline name: `G2P->MAUS`.
- Language: `Language independent (sampa)`.
- Output format: `Praat`.
- Keep everything: `false`.
- Expert options > `Imap mapping file (G2P)`.

The custom grapheme to phoneme (G2P) `imap` mapping file can be found in `data/varia/sqi-AL_map.txt`.

The service outputs Praat `.TextGrid` files containing the force-aligned segmentation of the three audio files of each speaker, which were saved in `data/recordings/derived/align/s<00>/`, where `<00>` is the speaker's ID number.

The `sentence.TextGrid` files needed to be manually changed by adding an extra tier which includes a sentence-level segmentation (MAUS output currently does not include a sentence-level segmentation tier).
The extra tier, called `sent`, was added as tier 1.
The intervals in `sent` contain the following labels according to the type of the sentence: `broad-focus`, `polar-q`, `narrow-focus-q`, `narrow-focus`.

The Praat script `code/get_postalign_chunks.praat` was then run to extract individual audio and TextGrid chunks which were later imported into the EMU database (see below).
The output of this script is saved in `data/recordings/derived/post-align/`.
This folder is ignored by dvc, to avoid data duplication (these files live in `data/alb-ipa_emuDB`).

## EMU database creation

The post-alignment chunks in `data/recordings/derived/post-align/` were then imported into an [EMU-SDMS](http://ips-lmu.github.io/EMU.html) database in `data/alb-ipa_emuDB/`.

The creation and configuration procedures are documented in `code/config/emu-config.Rmd`.

This script builds the annotation hierarchy and adds level definitions and tracks.

The annotation hierarchy is as follows:

- `ORT-MAU`: spelling.
- `KANN-MAU`: MAUS word transcription.
- `MAU`: MAUS segment transcription.

Two level definitions are added: `RELS` (EVENT) for the annotation of stop releases, and `VOI` (EVENT) for the annotation of voice onset (see below).

The tracks (formants, f0, DFT spectrum) were created with `emuR::add_ssffTrackDefinition()`, using on-the-fly functions from wrassp.

Formant tracks were obtained with `wrassp::praatFms()`.
This function uses Praat's algorithm.
The following settings were used:

- Number of formants: `5`.
- Maximum frequency: `5500`.
- Window length: `0.025`.
- Pre-emphasis from: `50`.

f0 tracks were obtained with `wrassp::ksvF0()`.

DFT spectrum tracks were added with `wrasp::dftSpectrum()`.

## Segmentation correction

The force-aligned segmentation generated by BAS was manually corrected with the the EMU webAPP by the researchers, as follows:

- Words: all segments were corrected.
- Sentences: only word boundaries were corrected.
- Story: nothing was corrected.

The formant trajectories were corrected with the EMU webAPP the word list files, but not in the sentences and story files.

## Annotation of stop releases and voice onset

The *time of the closure release* and the *voice onset time* was manually annotated for /p, b, t, d, k, g, ts, dz, tʃ, dʒ, t̻ʃ̻, d̻ʒ̻/, in the `RELS` and `VOI` event levels respectively.

## Data preparation

The file `code/r/prepare_data.Rmd` holds the code used to query the emuDB, process the ultrasound tongue imaging data, and extract the illustrative recordings and the recordings for plotting the example figures of VOT and affricates.

The following measures were extracted from the emuDB and packaged into `.rds` files, saved in `data/dataframes/`:

- Vowel formants.
- Plosive VOT.
- Fundamental frequency (f0) and syllable boundaries of the sentences that illustrate intonation.
- Spectral moments and centre of gravity (CoG) of fricatives and fricated portion of affricates.

For more information, see the code documentation in `code/r/prepare_data.Rmd`.

## Data plotting

The figures included in the manuscript were generated with the code in `code/r/prepare_plots.Rmd`.
This file also contains code for extra figures.

